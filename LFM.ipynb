{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Loading dataset from:  goodreads_reviews_young_adult_train.json\n",
      "Number of users:  175518\n",
      "Number of items:  78670\n",
      "Number of ratings:  1433940\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Loading dataset from:  goodreads_reviews_young_adult_val.json\n",
      "Number of users:  111805\n",
      "Number of items:  50707\n",
      "Number of ratings:  477980\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Loading dataset from:  goodreads_reviews_young_adult_test.json\n",
      "Number of users:  111807\n",
      "Number of items:  50783\n",
      "Number of ratings:  477980\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load json files into pandas dataframes\n",
    "\"\"\"\n",
    "def load_dataset(file_path):\n",
    "    data_frame = pd.read_json(file_path, lines=True)\n",
    "    print(\">\" * 50)\n",
    "    print(\"Loading dataset from: \", file_path)\n",
    "    print(\"Number of users: \", len(data_frame['user_id'].unique()))\n",
    "    print(\"Number of items: \", len(data_frame['item_id'].unique()))\n",
    "    print(\"Number of ratings: \", len(data_frame))\n",
    "    print(\">\" * 50)\n",
    "    return data_frame\n",
    "\n",
    "train_df = load_dataset('goodreads_reviews_young_adult_train.json') # training data\n",
    "val_df = load_dataset('goodreads_reviews_young_adult_val.json') # validation data\n",
    "test_df = load_dataset('goodreads_reviews_young_adult_test.json') # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6b6166a96cc86d35e638243d7733eb86</td>\n",
       "      <td>7171637</td>\n",
       "      <td>f1075451f04436d47b0abc5e7116599f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91ff00cc3a6a988904fb4420fac6d63c</td>\n",
       "      <td>428263</td>\n",
       "      <td>00d4600d1ff2726b72aa513abdc9f954</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da1a22733f209a30704ab4f55ca2af91</td>\n",
       "      <td>1217100</td>\n",
       "      <td>34a93cfc946ef38e9a0add45eae4b67f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599ce0c6a5a5cf980c38f20c24dd4711</td>\n",
       "      <td>9462775</td>\n",
       "      <td>cd30039367407745b4c33e7f98d73ce7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd894ab67e02dfcffb797c7380f5d87</td>\n",
       "      <td>7857408</td>\n",
       "      <td>bec621eb2e788344b173aeb594b3b553</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  item_id  \\\n",
       "0  6b6166a96cc86d35e638243d7733eb86  7171637   \n",
       "1  91ff00cc3a6a988904fb4420fac6d63c   428263   \n",
       "2  da1a22733f209a30704ab4f55ca2af91  1217100   \n",
       "3  599ce0c6a5a5cf980c38f20c24dd4711  9462775   \n",
       "4  4fd894ab67e02dfcffb797c7380f5d87  7857408   \n",
       "\n",
       "                          review_id  rating  \n",
       "0  f1075451f04436d47b0abc5e7116599f       0  \n",
       "1  00d4600d1ff2726b72aa513abdc9f954       3  \n",
       "2  34a93cfc946ef38e9a0add45eae4b67f       1  \n",
       "3  cd30039367407745b4c33e7f98d73ce7       3  \n",
       "4  bec621eb2e788344b173aeb594b3b553       3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map user_id and item_id to a sequence index, so that it ranges from [0, N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>map_userid</th>\n",
       "      <th>map_itemid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6b6166a96cc86d35e638243d7733eb86</td>\n",
       "      <td>7171637</td>\n",
       "      <td>f1075451f04436d47b0abc5e7116599f</td>\n",
       "      <td>0</td>\n",
       "      <td>73818</td>\n",
       "      <td>15771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91ff00cc3a6a988904fb4420fac6d63c</td>\n",
       "      <td>428263</td>\n",
       "      <td>00d4600d1ff2726b72aa513abdc9f954</td>\n",
       "      <td>3</td>\n",
       "      <td>100227</td>\n",
       "      <td>3308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da1a22733f209a30704ab4f55ca2af91</td>\n",
       "      <td>1217100</td>\n",
       "      <td>34a93cfc946ef38e9a0add45eae4b67f</td>\n",
       "      <td>1</td>\n",
       "      <td>149341</td>\n",
       "      <td>6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599ce0c6a5a5cf980c38f20c24dd4711</td>\n",
       "      <td>9462775</td>\n",
       "      <td>cd30039367407745b4c33e7f98d73ce7</td>\n",
       "      <td>3</td>\n",
       "      <td>61424</td>\n",
       "      <td>20436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd894ab67e02dfcffb797c7380f5d87</td>\n",
       "      <td>7857408</td>\n",
       "      <td>bec621eb2e788344b173aeb594b3b553</td>\n",
       "      <td>3</td>\n",
       "      <td>54879</td>\n",
       "      <td>17123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  item_id  \\\n",
       "0  6b6166a96cc86d35e638243d7733eb86  7171637   \n",
       "1  91ff00cc3a6a988904fb4420fac6d63c   428263   \n",
       "2  da1a22733f209a30704ab4f55ca2af91  1217100   \n",
       "3  599ce0c6a5a5cf980c38f20c24dd4711  9462775   \n",
       "4  4fd894ab67e02dfcffb797c7380f5d87  7857408   \n",
       "\n",
       "                          review_id  rating  map_userid  map_itemid  \n",
       "0  f1075451f04436d47b0abc5e7116599f       0       73818       15771  \n",
       "1  00d4600d1ff2726b72aa513abdc9f954       3      100227        3308  \n",
       "2  34a93cfc946ef38e9a0add45eae4b67f       1      149341        6932  \n",
       "3  cd30039367407745b4c33e7f98d73ce7       3       61424       20436  \n",
       "4  bec621eb2e788344b173aeb594b3b553       3       54879       17123  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_index(train_df):\n",
    "    user_id = train_df['user_id'].tolist()\n",
    "    item_id = train_df['item_id'].tolist()\n",
    "    sorted_user_id = sorted(set(user_id))\n",
    "    sorted_item_id = sorted(set(item_id))\n",
    "    userid_map = {user_id:i for i, user_id in enumerate(sorted_user_id)}\n",
    "    itemid_map = {item_id:i for i, item_id in enumerate(sorted_item_id)}\n",
    "    train_df['map_userid'] = train_df['user_id'].apply(lambda x: userid_map[x])\n",
    "    train_df['map_itemid'] = train_df['item_id'].apply(lambda x: itemid_map[x])\n",
    "\n",
    "    return train_df, userid_map, itemid_map\n",
    "\n",
    "train_df, userid_map, itemid_map = map_index(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bias:  3.7634559326052694\n",
      "The user specific bias of user id = “91ceb82d91493506532feb02ce751ce7”:  -0.9974984857967586\n",
      "The item specific bias of item id = “6931234”:  -0.24732690034720495\n"
     ]
    }
   ],
   "source": [
    "# Compute the global bias\n",
    "def compute_global_bias(train_df):\n",
    "    return train_df['rating'].mean()\n",
    "\n",
    "# Compute the user bias of a specific user\n",
    "def compute_user_bias(train_df, bg, user_id):\n",
    "    user_bias = train_df[train_df['user_id'] == user_id]['rating'].mean() - bg\n",
    "    return user_bias\n",
    "\n",
    "# Compute the item bias of a specific item\n",
    "def compute_item_bias(train_df, bg, item_id):\n",
    "    item_bias = train_df[train_df['item_id'] == item_id]['rating'].mean() - bg\n",
    "    return item_bias\n",
    "\n",
    "bg = compute_global_bias(train_df)\n",
    "print(\"Global bias: \", bg)\n",
    "user_bias = compute_user_bias(train_df, bg, '91ceb82d91493506532feb02ce751ce7')\n",
    "print(\"The user specific bias of user id = “91ceb82d91493506532feb02ce751ce7”: \", user_bias)\n",
    "item_bias = compute_item_bias(train_df, bg, 6931234)\n",
    "print(\"The item specific bias of item id = “6931234”: \", item_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement the regularized latent factor model without bias using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for computing RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(groundtruth, prediction):\n",
    "    sum = 0\n",
    "    for gt, pred in zip(groundtruth, prediction):\n",
    "        sum += (gt - pred) ** 2\n",
    "    mse = sum / len(groundtruth)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the regularized latent factor model without bias using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the latent factor model without bias\n",
    "class LFMwoBias:\n",
    "    def __init__(self, k, lr, lambda_1, lambda_2, userid_map, itemid_map):\n",
    "        self.k = k # number of latent factors\n",
    "        self.lr = lr # learning rate\n",
    "        # regularization hyperparameters\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        # user_id and item_id mapping\n",
    "        self.userid_map = userid_map\n",
    "        self.itemid_map = itemid_map\n",
    "        # initialize P and Q by random normal distribution\n",
    "        self.P = np.random.normal(loc=0, scale=1, size=(len(itemid_map), k))\n",
    "        self.Q = np.random.normal(loc=0, scale=1, size=(len(userid_map), k))\n",
    "    \n",
    "    # use SGD to train the model\n",
    "    def fit(self, train_df, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for row in train_df.itertuples():\n",
    "                user_id = self.userid_map[row.user_id]\n",
    "                item_id = self.itemid_map[row.item_id]\n",
    "                r = row.rating\n",
    "\n",
    "                # compute the prediction and loss\n",
    "                pred_r = np.dot(self.P[item_id], self.Q[user_id])\n",
    "                loss = r - pred_r\n",
    "\n",
    "                # compute the gradient\n",
    "                gradient_p = -2 * loss * self.Q[user_id] + 2 * self.lambda_2 * self.P[item_id]\n",
    "                gradient_q = -2 * loss * self.P[item_id] + 2 * self.lambda_1 * self.Q[user_id]\n",
    "\n",
    "                # update P and Q\n",
    "                self.P[item_id] = self.P[item_id] - self.lr * gradient_p\n",
    "                self.Q[user_id] = self.Q[user_id] - self.lr * gradient_q\n",
    "\n",
    "            # compute the RMSE for each epoch\n",
    "            preds = []\n",
    "            gts = train_df['rating'].tolist()\n",
    "            for row in train_df.itertuples():\n",
    "                user_id = self.userid_map[row.user_id]\n",
    "                item_id = self.itemid_map[row.item_id]\n",
    "                preds.append(np.dot(self.P[item_id], self.Q[user_id]))\n",
    "            rmse = RMSE(gts, preds)\n",
    "            print(\"Epoch: \", epoch+1, \", RMSE: \", rmse)\n",
    "\n",
    "    # predict the rating of a user-item pair\n",
    "    def predict(self, user_id, item_id):\n",
    "        # if the user_id or item_id is not in the training set, initialize P and Q by random normal distribution\n",
    "        if user_id not in self.userid_map:\n",
    "            q = np.random.normal(loc=0, scale=1, size=(self.k))\n",
    "        else:\n",
    "            q = self.Q[self.userid_map[user_id]] \n",
    "        if item_id not in self.itemid_map:\n",
    "            p = np.random.normal(loc=0, scale=1, size=(self.k))\n",
    "        else:\n",
    "            p = self.P[self.itemid_map[item_id]]\n",
    "        pred = np.dot(p, q)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model when k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , RMSE:  3.0879025118024415\n",
      "Epoch:  2 , RMSE:  2.17980890384628\n",
      "Epoch:  3 , RMSE:  1.7761222980429023\n",
      "Epoch:  4 , RMSE:  1.5446455886159298\n",
      "Epoch:  5 , RMSE:  1.3969658314302287\n",
      "Epoch:  6 , RMSE:  1.2967033655904485\n",
      "Epoch:  7 , RMSE:  1.2255497662474968\n",
      "Epoch:  8 , RMSE:  1.1733345139315552\n",
      "Epoch:  9 , RMSE:  1.1339969382748734\n",
      "Epoch:  10 , RMSE:  1.1037152964730346\n"
     ]
    }
   ],
   "source": [
    "model_k8 = LFMwoBias(k=8, lr=0.01, lambda_1=0.3, lambda_2=0.3, userid_map=userid_map, itemid_map=itemid_map)\n",
    "model_k8.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model when k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , RMSE:  3.4885440718829694\n",
      "Epoch:  2 , RMSE:  2.380794571128425\n",
      "Epoch:  3 , RMSE:  1.9247162951569834\n",
      "Epoch:  4 , RMSE:  1.6662961478223834\n",
      "Epoch:  5 , RMSE:  1.4989942621595547\n",
      "Epoch:  6 , RMSE:  1.3829382083093162\n",
      "Epoch:  7 , RMSE:  1.2988218008216301\n",
      "Epoch:  8 , RMSE:  1.2360227695993369\n",
      "Epoch:  9 , RMSE:  1.1881047827695514\n",
      "Epoch:  10 , RMSE:  1.1508967165336603\n"
     ]
    }
   ],
   "source": [
    "model_k4 = LFMwoBias(k=4, lr=0.01, lambda_1=0.3, lambda_2=0.3, userid_map=userid_map, itemid_map=itemid_map)\n",
    "model_k4.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model when k=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , RMSE:  2.915461639496118\n",
      "Epoch:  2 , RMSE:  2.032617240158386\n",
      "Epoch:  3 , RMSE:  1.6617923330559556\n",
      "Epoch:  4 , RMSE:  1.4585213787914093\n",
      "Epoch:  5 , RMSE:  1.3314851000112553\n",
      "Epoch:  6 , RMSE:  1.245524438502207\n",
      "Epoch:  7 , RMSE:  1.1841870349073593\n",
      "Epoch:  8 , RMSE:  1.1387453237883296\n",
      "Epoch:  9 , RMSE:  1.1041206665819667\n",
      "Epoch:  10 , RMSE:  1.0771488528101754\n"
     ]
    }
   ],
   "source": [
    "model_k16 = LFMwoBias(k=16, lr=0.01, lambda_1=0.3, lambda_2=0.3, userid_map=userid_map, itemid_map=itemid_map)\n",
    "model_k16.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE for each value of k on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the RMSE of a model on a dataset\n",
    "def cal_rmse(model, df):\n",
    "    preds = []\n",
    "    gts = df['rating'].tolist()\n",
    "    for row in df.itertuples():\n",
    "        user_id = row.user_id\n",
    "        item_id = row.item_id\n",
    "        pred = model.predict(user_id, item_id)\n",
    "        preds.append(pred)\n",
    "    rmse = RMSE(gts, preds)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation set of k=4:  1.8063713084919952\n",
      "RMSE on the validation set of k=8:  1.8883039935503667\n",
      "RMSE on the validation set of k=16:  2.007465162823557\n"
     ]
    }
   ],
   "source": [
    "rmse_k4 = cal_rmse(model_k4, val_df)\n",
    "rmse_k8 = cal_rmse(model_k8, val_df)\n",
    "rmse_k16 = cal_rmse(model_k16, val_df)\n",
    "\n",
    "print(\"RMSE on the validation set of k=4: \", rmse_k4)\n",
    "print(\"RMSE on the validation set of k=8: \", rmse_k8)\n",
    "print(\"RMSE on the validation set of k=16: \", rmse_k16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model when k=4 has the best RMSE.\n",
    "\n",
    "Compute its RMSE on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the best model on the test set:  1.799751940361155\n"
     ]
    }
   ],
   "source": [
    "model_best = model_k4\n",
    "rmse = cal_rmse(model_best, test_df)\n",
    "print(\"RMSE of the best model on the test set: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement the regularized latent factor model with bias using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute user bias and item bias for all users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_bias = compute_global_bias(train_df)\n",
    "train_df[\"user_bias\"] = train_df.groupby('user_id')['rating'].transform(lambda x: x.mean() - global_bias)\n",
    "train_df[\"item_bias\"] = train_df.groupby('item_id')['rating'].transform(lambda x: x.mean() - global_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>map_userid</th>\n",
       "      <th>map_itemid</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>item_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6b6166a96cc86d35e638243d7733eb86</td>\n",
       "      <td>7171637</td>\n",
       "      <td>f1075451f04436d47b0abc5e7116599f</td>\n",
       "      <td>0</td>\n",
       "      <td>73818</td>\n",
       "      <td>15771</td>\n",
       "      <td>-1.096789</td>\n",
       "      <td>0.343885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91ff00cc3a6a988904fb4420fac6d63c</td>\n",
       "      <td>428263</td>\n",
       "      <td>00d4600d1ff2726b72aa513abdc9f954</td>\n",
       "      <td>3</td>\n",
       "      <td>100227</td>\n",
       "      <td>3308</td>\n",
       "      <td>-0.172547</td>\n",
       "      <td>-0.142382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da1a22733f209a30704ab4f55ca2af91</td>\n",
       "      <td>1217100</td>\n",
       "      <td>34a93cfc946ef38e9a0add45eae4b67f</td>\n",
       "      <td>1</td>\n",
       "      <td>149341</td>\n",
       "      <td>6932</td>\n",
       "      <td>-1.528162</td>\n",
       "      <td>0.027971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599ce0c6a5a5cf980c38f20c24dd4711</td>\n",
       "      <td>9462775</td>\n",
       "      <td>cd30039367407745b4c33e7f98d73ce7</td>\n",
       "      <td>3</td>\n",
       "      <td>61424</td>\n",
       "      <td>20436</td>\n",
       "      <td>-0.529081</td>\n",
       "      <td>-0.173936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fd894ab67e02dfcffb797c7380f5d87</td>\n",
       "      <td>7857408</td>\n",
       "      <td>bec621eb2e788344b173aeb594b3b553</td>\n",
       "      <td>3</td>\n",
       "      <td>54879</td>\n",
       "      <td>17123</td>\n",
       "      <td>-0.319011</td>\n",
       "      <td>-1.263456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  item_id  \\\n",
       "0  6b6166a96cc86d35e638243d7733eb86  7171637   \n",
       "1  91ff00cc3a6a988904fb4420fac6d63c   428263   \n",
       "2  da1a22733f209a30704ab4f55ca2af91  1217100   \n",
       "3  599ce0c6a5a5cf980c38f20c24dd4711  9462775   \n",
       "4  4fd894ab67e02dfcffb797c7380f5d87  7857408   \n",
       "\n",
       "                          review_id  rating  map_userid  map_itemid  \\\n",
       "0  f1075451f04436d47b0abc5e7116599f       0       73818       15771   \n",
       "1  00d4600d1ff2726b72aa513abdc9f954       3      100227        3308   \n",
       "2  34a93cfc946ef38e9a0add45eae4b67f       1      149341        6932   \n",
       "3  cd30039367407745b4c33e7f98d73ce7       3       61424       20436   \n",
       "4  bec621eb2e788344b173aeb594b3b553       3       54879       17123   \n",
       "\n",
       "   user_bias  item_bias  \n",
       "0  -1.096789   0.343885  \n",
       "1  -0.172547  -0.142382  \n",
       "2  -1.528162   0.027971  \n",
       "3  -0.529081  -0.173936  \n",
       "4  -0.319011  -1.263456  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the regularized latent factor model with bias using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the latent factor model with bias\n",
    "class LFMwBias:\n",
    "    def __init__(self, k, lr, lambda_1, lambda_2, lambda_3, lambda_4, userid_map, itemid_map):\n",
    "\n",
    "        self.k = k # number of latent factors\n",
    "        self.lr = lr # learning rate\n",
    "        # regularization hyperparameters\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.lambda_3 = lambda_3\n",
    "        self.lambda_4 = lambda_4\n",
    "        # user_id and item_id mapping\n",
    "        self.userid_map = userid_map\n",
    "        self.itemid_map = itemid_map\n",
    "        # initialize P and Q by random normal distribution\n",
    "        self.P = np.random.normal(loc=0, scale=1, size=(len(itemid_map), k))\n",
    "        self.Q = np.random.normal(loc=0, scale=1, size=(len(userid_map), k))\n",
    "\n",
    "    # use SGD to train the model\n",
    "    def fit(self, train_df, epochs):\n",
    "        self.global_bias = compute_global_bias(train_df)\n",
    "        df_user_bias = train_df.groupby('user_id').agg({'user_bias': 'max'})\n",
    "        df_item_bias = train_df.groupby('item_id').agg({'item_bias': 'max'})\n",
    "        self.user_bias = {user_id: bias for user_id, bias in zip(df_user_bias.index, df_user_bias['user_bias'])}\n",
    "        self.item_bias = {item_id: bias for item_id, bias in zip(df_item_bias.index, df_item_bias['item_bias'])}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for row in train_df.itertuples():\n",
    "                ori_user_id = row.user_id\n",
    "                ori_item_id = row.item_id\n",
    "                user_id = self.userid_map[ori_user_id]\n",
    "                item_id = self.itemid_map[ori_item_id]\n",
    "                r = row.rating\n",
    "\n",
    "                # get the user bias and item bias\n",
    "                b_user = self.user_bias[ori_user_id]\n",
    "                b_item = self.item_bias[ori_item_id]\n",
    "\n",
    "                # compute the prediction and loss\n",
    "                pred_r = np.dot(self.P[item_id], self.Q[user_id]) + self.global_bias + b_user + b_item\n",
    "                loss = r - pred_r\n",
    "\n",
    "                # compute the gradient\n",
    "                gradient_p = -2 * loss * self.Q[user_id] + 2 * self.lambda_2 * self.P[item_id]\n",
    "                gradient_q = -2 * loss * self.P[item_id] + 2 * self.lambda_1 * self.Q[user_id]\n",
    "                gradient_b_user = - 2 * loss + 2 * self.lambda_3 * b_user\n",
    "                gradient_b_item = -2 * loss + 2 * self.lambda_4 * b_item\n",
    "\n",
    "                # update P, Q, user_bias and item_bias\n",
    "                self.P[item_id] = self.P[item_id] - self.lr * gradient_p\n",
    "                self.Q[user_id] = self.Q[user_id] - self.lr * gradient_q\n",
    "                self.user_bias[ori_user_id] = b_user - self.lr * gradient_b_user\n",
    "                self.item_bias[ori_item_id] = b_item - self.lr * gradient_b_item\n",
    "\n",
    "            # compute the RMSE for each epoch\n",
    "            preds = []\n",
    "            gts = train_df['rating'].tolist()\n",
    "            for row in train_df.itertuples():\n",
    "                ori_user_id = row.user_id\n",
    "                ori_item_id = row.item_id\n",
    "                user_id = self.userid_map[ori_user_id]\n",
    "                item_id = self.itemid_map[ori_item_id]\n",
    "                b_user = self.user_bias[ori_user_id]\n",
    "                b_item = self.item_bias[ori_item_id]\n",
    "                pred = np.dot(self.P[item_id], self.Q[user_id]) + self.global_bias + b_user + b_item\n",
    "                preds.append(pred)\n",
    "            rmse = RMSE(gts, preds)\n",
    "            print(\"Epoch: \", epoch+1, \", RMSE: \", rmse)\n",
    "\n",
    "    # predict the rating of a user-item pair\n",
    "    def predict(self, user_id, item_id):\n",
    "        # if the user_id or item_id is not in the training set, initialize P and Q by random normal distribution\n",
    "        # if the user_id or item_id is not in the training set, initialize user_bias and item_bias by 0\n",
    "        if user_id not in self.userid_map:\n",
    "            q = np.random.normal(loc=0, scale=1, size=(self.k))\n",
    "            b_user = 0\n",
    "        else:\n",
    "            q = self.Q[self.userid_map[user_id]] \n",
    "            b_user = self.user_bias[user_id]\n",
    "        if item_id not in self.itemid_map:\n",
    "            p = np.random.normal(loc=0, scale=1, size=(self.k))\n",
    "            b_item = 0\n",
    "        else:\n",
    "            p = self.P[self.itemid_map[item_id]]\n",
    "            b_item = self.item_bias[item_id]\n",
    "        pred = np.dot(p, q) + self.global_bias + b_user + b_item\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model when k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , RMSE:  1.0741372910830298\n",
      "Epoch:  2 , RMSE:  0.9773417704528685\n",
      "Epoch:  3 , RMSE:  0.94712139775978\n",
      "Epoch:  4 , RMSE:  0.9348071364424908\n",
      "Epoch:  5 , RMSE:  0.929070574668833\n",
      "Epoch:  6 , RMSE:  0.9261940058972807\n",
      "Epoch:  7 , RMSE:  0.9247056768372163\n",
      "Epoch:  8 , RMSE:  0.9239454774921092\n",
      "Epoch:  9 , RMSE:  0.9235890568712566\n",
      "Epoch:  10 , RMSE:  0.9234654446951402\n"
     ]
    }
   ],
   "source": [
    "model_k8 = LFMwBias(k=8, lr=0.01, lambda_1=0.3, lambda_2=0.3, lambda_3=0.3, lambda_4=0.3, userid_map=userid_map, itemid_map=itemid_map)\n",
    "model_k8.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the learned user-specific bias of the user with user id= “91ceb82d91493506532feb02ce751ce7” , and the learned item-specific bias of the item with item id = “6931234”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user bias of “91ceb82d91493506532feb02ce751ce7”: -0.5628730990492314\n",
      "item bias of “6931234”: -0.16827633953398888\n"
     ]
    }
   ],
   "source": [
    "print(\"user bias of “91ceb82d91493506532feb02ce751ce7”:\", model_k8.user_bias['91ceb82d91493506532feb02ce751ce7'])\n",
    "print(\"item bias of “6931234”:\", model_k8.item_bias[6931234])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model when k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , RMSE:  1.0457490098646074\n",
      "Epoch:  2 , RMSE:  0.9846275246526599\n",
      "Epoch:  3 , RMSE:  0.9629834774516193\n",
      "Epoch:  4 , RMSE:  0.9529038558526138\n",
      "Epoch:  5 , RMSE:  0.9475175061120047\n",
      "Epoch:  6 , RMSE:  0.9443802171303045\n",
      "Epoch:  7 , RMSE:  0.9424394016151174\n",
      "Epoch:  8 , RMSE:  0.9411832079655854\n",
      "Epoch:  9 , RMSE:  0.9403404573329069\n",
      "Epoch:  10 , RMSE:  0.9397579076650767\n"
     ]
    }
   ],
   "source": [
    "model_k4 = LFMwBias(k=4, lr=0.01, lambda_1=0.3, lambda_2=0.3, lambda_3=0.3, lambda_4=0.3, userid_map=userid_map, itemid_map=itemid_map)\n",
    "model_k4.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model when k=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , RMSE:  1.0481965364430295\n",
      "Epoch:  2 , RMSE:  0.937822938078228\n",
      "Epoch:  3 , RMSE:  0.9115104027617754\n",
      "Epoch:  4 , RMSE:  0.9031351153421378\n",
      "Epoch:  5 , RMSE:  0.9002586247128521\n",
      "Epoch:  6 , RMSE:  0.8994553357498708\n",
      "Epoch:  7 , RMSE:  0.8995409036164567\n",
      "Epoch:  8 , RMSE:  0.9000363080531647\n",
      "Epoch:  9 , RMSE:  0.9007245191804905\n",
      "Epoch:  10 , RMSE:  0.9014987193034989\n"
     ]
    }
   ],
   "source": [
    "model_k16 = LFMwBias(k=16, lr=0.01, lambda_1=0.3, lambda_2=0.3, lambda_3=0.3, lambda_4=0.3, userid_map=userid_map, itemid_map=itemid_map)\n",
    "model_k16.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE for each value of k on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation set of k=4:  1.1640240712787042\n",
      "RMSE on the validation set of k=8:  1.1971190191156318\n",
      "RMSE on the validation set of k=16:  1.2608739517781484\n"
     ]
    }
   ],
   "source": [
    "rmse_k4 = cal_rmse(model_k4, val_df)\n",
    "rmse_k8 = cal_rmse(model_k8, val_df)\n",
    "rmse_k16 = cal_rmse(model_k16, val_df)\n",
    "\n",
    "print(\"RMSE on the validation set of k=4: \", rmse_k4)\n",
    "print(\"RMSE on the validation set of k=8: \", rmse_k8)\n",
    "print(\"RMSE on the validation set of k=16: \", rmse_k16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model when k=4 has the best RMSE.\n",
    "\n",
    "Compute its RMSE on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set:  1.1613597168338194\n"
     ]
    }
   ],
   "source": [
    "model_best = model_k4\n",
    "rmse = cal_rmse(model_best, test_df)\n",
    "print(\"RMSE on the test set: \", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
